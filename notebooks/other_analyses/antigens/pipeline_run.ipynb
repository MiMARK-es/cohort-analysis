{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sbg workspace and local utils\n",
    "import sys\n",
    "sys.path.append('/home/leandro/Dropbox/workspacesbg/sbg/')\n",
    "sys.path.append('../../../code/')\n",
    "\n",
    "from sbg.orf.Orf import OnlineOrf\n",
    "from sbg.structure.AlphaFoldHandler import AlphaFoldHandler\n",
    "from sbg.structure.Structure import Structure\n",
    "from sbg.common.FileHandler import FileHandler\n",
    "from sbg.scripts.foldx.TangoHandler import TangoHandler\n",
    "\n",
    "import pipeline_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from sequence_utils import highlight_sequence, align_sequences_biopython, display_alignment_with_highlighting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from data/protein_data.csv\n",
    "data = pd.read_csv('data/protein_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing P07355 ANXA2_HUMAN, 1 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing O00425 IF2B3_HUMAN, 2 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing O15392 BIRC5_HUMAN, 3 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P00749 UROK_HUMAN, 4 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P02787 TRFE_HUMAN, 5 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P03372 ESR1_HUMAN, 6 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P04792 HSPB1_HUMAN, 7 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P07339 CATD_HUMAN, 8 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P08253 MMP2_HUMAN, 9 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P09603 CSF1_HUMAN, 10 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P10415 BCL2_HUMAN, 11 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P11166 GTR1_HUMAN, 12 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P14780 MMP9_HUMAN, 13 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P15692 VEGFA_HUMAN, 14 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P15941 MUC1_HUMAN, 15 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P17813 EGLN_HUMAN, 16 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P35354 PGH2_HUMAN, 17 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P38936 CDN1A_HUMAN, 18 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P42771 CD2A1_HUMAN, 19 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P60484 PTEN_HUMAN, 20 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P61604 CH10_HUMAN, 21 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing Q13938 CAYP1_HUMAN, 22 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing Q14508 WFDC2_HUMAN, 23 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P12830 CADH1_HUMAN, 24 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P11802 CDK4_HUMAN, 25 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P17661 DESM_HUMAN, 26 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing O14497 ARI1A_HUMAN, 27 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing Q07812 BAX_HUMAN, 28 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P04626 ERBB2_HUMAN, 29 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P04637 P53_HUMAN, 30 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing Q8WXI7 MUC16_HUMAN, 31 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P46013 KI67_HUMAN, 32 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing Q9Y251 HPSE_HUMAN, 33 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P35221 CTNA1_HUMAN, 34 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing Q15118 PDK1_HUMAN, 35 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P43405 KSYK_HUMAN, 36 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing Q92878 RAD50_HUMAN, 37 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing O96017 CHK2_HUMAN, 38 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P24864 uniprot_accession\n",
      "P24864    CCNE1_HUMAN\n",
      "P24864    CCNE1_HUMAN\n",
      "Name: swiss_prot, dtype: object, 39 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P06493 CDK1_HUMAN, 40 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P08243 ASNS_HUMAN, 41 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P15328 FOLR1_HUMAN, 42 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P40692 MLH1_HUMAN, 43 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P14618 KPY1_HUMAN, 44 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P07237 PDIA1_HUMAN, 45 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P06401 PRGR_HUMAN, 46 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P19544 WT1_HUMAN, 47 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing O14493 CLD4_HUMAN, 48 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P16035 TIMP2_HUMAN, 49 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P35222 CTNB1_HUMAN, 50 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P48023 TNFL6_HUMAN, 51 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing A2N4P8 A2N4P8_HUMAN, 52 of 505\n",
      "Gene 'IL2R' not found in the expression data.\n",
      "Processing O95997 PTTG1_HUMAN, 53 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P00533 EGFR_HUMAN, 54 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P01106 MYC_HUMAN, 55 of 505\n",
      "Processing P01236 PRL_HUMAN, 56 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P01241 SOMA_HUMAN, 57 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P02647 APOA1_HUMAN, 58 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P02741 CRP_HUMAN, 59 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P02766 TTHY_HUMAN, 60 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P02771 FETA_HUMAN, 61 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P04083 ANXA1_HUMAN, 62 of 505\n",
      "Not enough samples in one or both groups to perform statistical comparison.\n",
      "Processing P08254 MMP3_HUMAN, 63 of 505\n"
     ]
    }
   ],
   "source": [
    "entry = 0\n",
    "for up_acc in data.index:\n",
    "    try:\n",
    "        entry += 1\n",
    "        print(f'Processing {up_acc} {data.loc[up_acc, 'swiss_prot']}, {entry} of {len(data.index)}')\n",
    "\n",
    "        results_dir = f'/home/leandro/Insync/gdrive/Mimark/code/cohort-analysis/notebooks/other_analyses/antigens/data/results/{up_acc[0:2]}/{up_acc}/'\n",
    "        FileHandler.ensureDir(results_dir)\n",
    "\n",
    "        # Step 1: Get the Uniprot object\n",
    "        step = 1\n",
    "        uniprot_object = OnlineOrf(up_acc)\n",
    "        step = 1.1\n",
    "        glycosilation_sites = uniprot_object.getGlycosylationSites()\n",
    "        if len(uniprot_object.getGlycosylationSites()) > 0:\n",
    "            glycosylation_df = pd.DataFrame(uniprot_object.getGlycosylationSites(), columns=['res', 'glycosylation'])\n",
    "            glycosylation_df.to_csv(results_dir + f'{up_acc}_glycosylation.csv')\n",
    "        \n",
    "        step = 1.2\n",
    "        modified_residues = uniprot_object.getModifiedResidues()\n",
    "        if len(uniprot_object.getModifiedResidues()) > 0:\n",
    "            modified_residues_df = pd.DataFrame(uniprot_object.getModifiedResidues(), columns=['res', 'modification'])\n",
    "            modified_residues_df.to_csv(results_dir + f'{up_acc}_modifications.csv')\n",
    "        \n",
    "        # step = 1.3\n",
    "        # try:\n",
    "        #     isoforms = uniprot_object.getIsoforms()\n",
    "        # except:\n",
    "        #     isoforms = []\n",
    "        # step = 1.4\n",
    "        # uniprot_string_id = uniprot_object.getStringId()\n",
    "        # step = 1.5\n",
    "        # try:\n",
    "        #     subcellular_location = uniprot_object.getSubcellularLocation()\n",
    "        # except:\n",
    "        #     subcellular_location = None\n",
    "        # step=1.6\n",
    "        # crytals = uniprot_object.getCrystals()\n",
    "\n",
    "        # # Step 2: Get the AlphaFold object\n",
    "        # step = 2\n",
    "        # alphafold_object = AlphaFoldHandler().get_model(up_acc)\n",
    "\n",
    "        # # Step 3: Run discotope 3.0 and save the results, then load them\n",
    "        # step = 3\n",
    "        # if alphafold_object is not None:\n",
    "        #     discotope3_file = f'{up_acc}_A_discotope3.csv'\n",
    "        #     # If no results, run discotope\n",
    "        #     # if not FileHandler.fileExists(path=results_dir + discotope3_file):\n",
    "        #     #     pf.run_discotope(up_acc, save_to=results_dir)\n",
    "            \n",
    "        #     # Now, if the results are there, load them\n",
    "        #     if FileHandler.fileExists(path=results_dir + discotope3_file):\n",
    "        #         discotope_results = pd.read_csv(results_dir + discotope3_file, index_col=0)\n",
    "        #     else:\n",
    "        #         discotope_results = None\n",
    "\n",
    "        # Step 4: Compute the expression \n",
    "        step = 4\n",
    "        exp_file = f'{up_acc}_exp_results.csv'\n",
    "        #if FileHandler.fileExists(results_dir + exp_file):\n",
    "        #    exp_results = pd.read_csv(results_dir + exp_file, index_col=0)\n",
    "        #else:\n",
    "        try:\n",
    "            exp_auc, exp_normal, exp_cancer = pf.compare_gene_expression(gene_name=uniprot_object.getGeneName(), up_acc=up_acc, save_to=results_dir)\n",
    "        except:\n",
    "            exp_auc, exp_normal, exp_cancer = None, None, None\n",
    "        \n",
    "        exp_results = pd.DataFrame({'exp_auc': [exp_auc], 'exp_normal': [exp_normal], 'exp_cancer': [exp_cancer]})\n",
    "        exp_results.to_csv(results_dir + exp_file)\n",
    "\n",
    "        # # Step 5: Align the isoforms\n",
    "        # step = 5\n",
    "        # if not FileHandler.fileExists(results_dir + f'{up_acc}_isoforms_alignment.html') and len(isoforms) > 1:\n",
    "        #     secuences = []\n",
    "        #     names = []\n",
    "        #     for isoform in isoforms:\n",
    "        #         isoform_obj = OnlineOrf(isoform)\n",
    "        #         secuences.append(isoform_obj.getSequence())\n",
    "        #         names.append(isoform)\n",
    "        #     alignment = align_sequences_biopython(secuences, names)\n",
    "        #     display_alignment_with_highlighting(alignment, save_to=results_dir + f'{up_acc}_isoforms_alignment.html')\n",
    "\n",
    "        # # Step 6: Compute the aggregation propensity\n",
    "        # step = 6\n",
    "        # if alphafold_object is not None:\n",
    "        #     if not FileHandler.fileExists(results_dir + f'{up_acc}_agg.txt'):\n",
    "        #         TangoHandler.getAggregation(alphafold_object,results_dir)\n",
    "\n",
    "        #     agg_df = pd.read_csv(results_dir + f'{up_acc}_agg.txt', sep='\\t', header=0, index_col=\"res\")[[\"Aggregation\"]]\n",
    "        \n",
    "        # # Step 7: Get interaction partners\n",
    "        # step = 7\n",
    "        # if not FileHandler.fileExists(results_dir + f'{up_acc}_interactors.tsv'):\n",
    "        #     interactors = pf.get_interactors(uniprot_string_id, up_acc, save_to=results_dir)\n",
    "        # else:\n",
    "        #     interactors = pd.read_csv(results_dir + f'{up_acc}_interactors.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "        # # Step 8: Get the protein homology\n",
    "        # step = 8\n",
    "        # if not FileHandler.fileExists(results_dir + f'{up_acc}_homologs.tsv'):\n",
    "        #     homology = pf.get_homologs(uniprot_object.getGeneName(), up_acc, save_to=results_dir)\n",
    "        # else:\n",
    "        #     homology = pd.read_csv(results_dir + f'{up_acc}_homologs.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "        # # Step 9: Get the protein structures bioassemblies to check for homo and multimers\n",
    "        # step = 9\n",
    "        # if not FileHandler.fileExists(results_dir + f'{up_acc}_bioassemblies.csv'):\n",
    "        #     try:\n",
    "        #         all_dataframes = []\n",
    "        #         for crystal in crytals:\n",
    "        #             structure = Structure(crystal, replaceExistent=False)\n",
    "        #             df = structure.analyzeStructureType()\n",
    "        #             df['crystal_id'] = crystal\n",
    "        #             all_dataframes.append(df)\n",
    "\n",
    "        #         if len(all_dataframes) > 1:\n",
    "        #             bioassemblies_df = pd.concat(all_dataframes)\n",
    "        #         elif len(all_dataframes) == 1:\n",
    "        #             bioassemblies_df = all_dataframes[0]\n",
    "        #         else:\n",
    "        #             bioassemblies_df = None\n",
    "\n",
    "        #         if len(all_dataframes) > 0:\n",
    "        #             bioassemblies_df.to_csv(results_dir+f'{up_acc}_bioassemblies.csv')\n",
    "        #     except:\n",
    "        #         bioassemblies_df = None\n",
    "        # else:\n",
    "        #     bioassemblies_df = pd.read_csv(results_dir + f'{up_acc}_bioassemblies.csv')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error with {up_acc} in step {step}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary: epitopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_accs = {\n",
    "    \"KPYM\": \"P14618\",\n",
    "    \"MMP9\": \"P14780\",\n",
    "    \"HSPB1\": \"P04792\",\n",
    "    \"AGRIN\": \"O00468\",\n",
    "    \"CLIC1\": \"O00299\"\n",
    "}\n",
    "\n",
    "epitopes = {\n",
    "    \"KPYM\": [\"EAVRMQHLIARE\"],\n",
    "    \"MMP9\": [\"TFLGKEY\", \"GYPFDGKD\"],\n",
    "    \"HSPB1\": [\"KDGVV\"],\n",
    "    \"AGRIN\": [\"RLELSRHW\", \"FVGAGLRGC\", \"NPCHGAAPC\", \"RDRRLEF\", \"GHPCLNGASC\", \"VCLCPGGF\"],\n",
    "    \"CLIC1\": [\"KRRTE\", \"QVELF\", \"KRRTET\"] \n",
    "}\n",
    "\n",
    "\n",
    "up_objs = {k: OnlineOrf(v) for k, v in up_accs.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing KPYM\n",
      "Epitope: EAVRMQHLIARE\n",
      "Positions: [(372, 384)]\n",
      "\n",
      "\n",
      "\n",
      "Processing MMP9\n",
      "Epitope: TFLGKEY\n",
      "Positions: [(351, 358)]\n",
      "Epitope: GYPFDGKD\n",
      "Positions: [(177, 185)]\n",
      "\n",
      "\n",
      "\n",
      "Processing HSPB1\n",
      "Epitope: KDGVV\n",
      "Positions: [(113, 118)]\n",
      "\n",
      "\n",
      "\n",
      "Processing AGRIN\n",
      "Epitope: RLELSRHW\n",
      "Positions: [(1455, 1463)]\n",
      "Epitope: FVGAGLRGC\n",
      "Positions: [(1510, 1519)]\n",
      "Epitope: NPCHGAAPC\n",
      "Positions: [(1594, 1603)]\n",
      "Epitope: RDRRLEF\n",
      "Positions: [(1695, 1702)]\n",
      "Epitope: GHPCLNGASC\n",
      "Positions: [(1826, 1836)]\n",
      "Epitope: VCLCPGGF\n",
      "Positions: [(1843, 1851)]\n",
      "\n",
      "\n",
      "\n",
      "Processing CLIC1\n",
      "Epitope: KRRTE\n",
      "Positions: [(48, 53)]\n",
      "Epitope: QVELF\n",
      "Positions: [(6, 11)]\n",
      "Epitope: KRRTET\n",
      "Positions: [(48, 54)]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_all_epitopes(seq, epitope):\n",
    "    positions = []\n",
    "    for i in range(len(seq) - len(epitope)):\n",
    "        if seq[i:i+len(epitope)] == epitope:\n",
    "            positions.append((i, i+len(epitope)))\n",
    "    return positions\n",
    "\n",
    "for up in up_objs.keys():\n",
    "    print(f'Processing {up}')\n",
    "    up_obj = up_objs[up]\n",
    "    seq = up_obj.getSequence()\n",
    "\n",
    "    for epitope in epitopes[up]:\n",
    "        print(f'Epitope: {epitope}')\n",
    "        print(f'Positions: {find_all_epitopes(seq, epitope)}')\n",
    "\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
