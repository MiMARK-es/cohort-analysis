{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expression_data(expression_file, samples, genes_of_interest, temp_file=\"filtered_expression_data.txt\"):\n",
    "    \"\"\"\n",
    "    Load expression data and filter for relevant samples and genes.\n",
    "\n",
    "    Parameters:\n",
    "    - expression_file (str): Path to the expression data file.\n",
    "    - samples (list): List of sample IDs to include.\n",
    "    - genes_of_interest (list): List of gene names to include.\n",
    "    - temp_file (str): Temporary file to store filtered expression data.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Expression data filtered for the given samples and genes.\n",
    "    \"\"\"\n",
    "    print(\"Filtering expression data...\")\n",
    "\n",
    "    # Read the header to find matching sample columns\n",
    "    with open(expression_file, \"r\") as f:\n",
    "        header = f.readline().strip().split('\\t')\n",
    "\n",
    "    # Determine which columns to keep\n",
    "    columns_to_keep = [0] + [i for i, col in enumerate(header) if col in samples]\n",
    "\n",
    "    if len(columns_to_keep) <= 1:\n",
    "        print(\"No matching samples found in the header.\")\n",
    "        raise ValueError(\"No matching samples found in expression data.\")\n",
    "\n",
    "    # Write filtered data to a temporary file\n",
    "    with open(temp_file, \"w\") as out_f:\n",
    "        # Write the header\n",
    "        out_f.write('\\t'.join([header[i] for i in columns_to_keep]) + '\\n')\n",
    "\n",
    "        # Filter rows based on genes of interest\n",
    "        for line in open(expression_file, \"r\"):\n",
    "            split_line = line.strip().split('\\t')\n",
    "            gene_name = split_line[0]  # First column contains the gene names\n",
    "            if gene_name in genes_of_interest:\n",
    "                out_f.write('\\t'.join([split_line[i] for i in columns_to_keep]) + '\\n')\n",
    "\n",
    "    # Load the filtered data into a DataFrame\n",
    "    print(\"Loading filtered data into DataFrame...\")\n",
    "    expr_df = pd.read_csv(temp_file, sep='\\t',header=0, encoding='latin1')\n",
    "\n",
    "    # Return the filtered DataFrame\n",
    "    return expr_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdc_file_ids(project_id=\"TCGA-UCEC\", data_type=\"Clinical Supplement\"):\n",
    "    \"\"\"\n",
    "    Retrieve GDC file IDs for a given project and data type.\n",
    "\n",
    "    Parameters:\n",
    "    - project_id (str): GDC project ID (e.g., \"TCGA-UCEC\").\n",
    "    - data_type (str): Type of data to filter for (e.g., \"Clinical Supplement\").\n",
    "\n",
    "    Returns:\n",
    "    - list: List of file IDs.\n",
    "    \"\"\"\n",
    "    GDC_FILES_URL = \"https://api.gdc.cancer.gov/files\"\n",
    "    params = {\n",
    "        \"filters\": {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"in\", \"content\": {\"field\": \"cases.project.project_id\", \"value\": [project_id]}},\n",
    "                {\"op\": \"in\", \"content\": {\"field\": \"data_category\", \"value\": [\"Clinical\"]}},\n",
    "                {\"op\": \"in\", \"content\": {\"field\": \"data_type\", \"value\": [data_type]}}\n",
    "            ]\n",
    "        },\n",
    "        \"format\": \"JSON\",\n",
    "        \"size\": 100\n",
    "    }\n",
    "\n",
    "    response = requests.post(GDC_FILES_URL, json=params)\n",
    "    if response.status_code == 200:\n",
    "        file_data = response.json()[\"data\"][\"hits\"]\n",
    "        file_ids = [file[\"file_id\"] for file in file_data]\n",
    "        print(f\"Retrieved {len(file_ids)} file IDs.\")\n",
    "        return file_ids\n",
    "    else:\n",
    "        print(f\"Failed to retrieve file IDs. Status code: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: string indices must be integers, not 'str'\n",
      "Response text: {\"data\": {\"hits\": [], \"pagination\": {\"count\": 0, \"total\": 0, \"size\": 10000, \"from\": 0, \"sort\": \"\", \"page\": 0, \"pages\": 0}}, \"warnings\": {}}\n",
      "Error parsing JSON: string indices must be integers, not 'str'\n",
      "Response text: {\"data\": {\"hits\": [], \"pagination\": {\"count\": 0, \"total\": 0, \"size\": 10000, \"from\": 0, \"sort\": \"\", \"page\": 0, \"pages\": 0}}, \"warnings\": {}}\n",
      "No file IDs found for GTEx samples.\n"
     ]
    }
   ],
   "source": [
    "project_id = \"GTEX\"  # Replace with your project ID\n",
    "file_ids = get_gdc_file_ids(project_id=project_id, data_type=\"Clinical Supplement\")\n",
    "\n",
    "# Step 2: Download XML files\n",
    "if file_ids:\n",
    "    download_xml_files(file_ids, xml_dir)\n",
    "else:\n",
    "    print(\"No file IDs found. Exiting.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Namespace mapping for XML parsing\n",
    "NAMESPACES = {\n",
    "    \"clin_shared\": \"http://tcga.nci/bcr/xml/clinical/shared/2.7\",\n",
    "    \"shared\": \"http://tcga.nci/bcr/xml/shared/2.7\",\n",
    "}\n",
    "\n",
    "# GDC API base URL\n",
    "GDC_API_URL = \"https://api.gdc.cancer.gov/data/\"\n",
    "\n",
    "def download_xml_files(file_ids, output_dir):\n",
    "    \"\"\"\n",
    "    Download XML files from the GDC Data Portal using file IDs.\n",
    "\n",
    "    Parameters:\n",
    "    - file_ids (list): List of GDC file IDs to download.\n",
    "    - output_dir (str): Directory to save the downloaded XML files.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for file_id in file_ids:\n",
    "        print(f\"Downloading file ID: {file_id}\")\n",
    "        response = requests.get(GDC_API_URL + file_id, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            content_disposition = response.headers.get(\"Content-Disposition\", \"\")\n",
    "            file_name = content_disposition.split(\"filename=\")[-1].strip('\"') if \"filename=\" in content_disposition else f\"{file_id}.xml\"\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Downloaded: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download file ID: {file_id}. Status code: {response.status_code}\")\n",
    "\n",
    "def extract_race_from_xml(xml_file):\n",
    "    \"\"\"\n",
    "    Extract race information from a single XML file using lxml.\n",
    "\n",
    "    Parameters:\n",
    "    - xml_file (str): Path to the XML file.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Mapping of patient ID to race.\n",
    "    \"\"\"\n",
    "    tree = etree.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    race_data = {}\n",
    "    for race_elem in root.findall(\".//clin_shared:race_list/clin_shared:race\", NAMESPACES):\n",
    "        race = race_elem.text\n",
    "        parent = race_elem.getparent().getparent()  # Move up to the patient level\n",
    "        patient_id_elem = parent.find(\"shared:bcr_patient_barcode\", NAMESPACES)\n",
    "        if patient_id_elem is not None:\n",
    "            patient_id = patient_id_elem.text\n",
    "            # Normalize patient ID format to match phenotype file\n",
    "            race_data[f\"{patient_id}-01\"] = race  # Add '-01' as a common suffix\n",
    "    return race_data\n",
    "\n",
    "def load_race_data(xml_dir):\n",
    "    \"\"\"\n",
    "    Load race data from multiple XML files.\n",
    "\n",
    "    Parameters:\n",
    "    - xml_dir (str): Directory containing XML files.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame with patient IDs and race.\n",
    "    \"\"\"\n",
    "    race_dict = {}\n",
    "    for xml_file in os.listdir(xml_dir):\n",
    "        if xml_file.endswith(\".xml\"):\n",
    "            full_path = os.path.join(xml_dir, xml_file)\n",
    "            race_dict.update(extract_race_from_xml(full_path))\n",
    "    \n",
    "    return pd.DataFrame(list(race_dict.items()), columns=[\"sample\", \"race\"])\n",
    "\n",
    "def load_phenotype_data(phenotype_file, race_df):\n",
    "    \"\"\"\n",
    "    Load phenotype data and merge with race data.\n",
    "\n",
    "    Parameters:\n",
    "    - phenotype_file (str): Path to the phenotype data file.\n",
    "    - race_df (DataFrame): Race data.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Merged phenotype and race data.\n",
    "    \"\"\"\n",
    "    print(\"Reading phenotype data...\")\n",
    "    phenotype_df = pd.read_csv(phenotype_file, sep='\\t', encoding='latin1')\n",
    "\n",
    "    # Normalize phenotype sample IDs to patient-level IDs\n",
    "    phenotype_df['patient_id'] = phenotype_df['sample'].str.extract(r'(^TCGA-\\w\\w-\\w\\w\\w\\w)')\n",
    "\n",
    "    # Merge using patient-level IDs\n",
    "    merged_df = pd.merge(\n",
    "        phenotype_df,\n",
    "        race_df.rename(columns={'sample': 'patient_id'}),\n",
    "        on='patient_id',\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"Merged phenotype data with race.\")\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def analyze_gene_expression_by_race(expression_df, merged_df, genes_of_interest):\n",
    "    \"\"\"\n",
    "    Analyze gene expression differences by race.\n",
    "\n",
    "    Parameters:\n",
    "    - expression_df (DataFrame): Expression data.\n",
    "    - merged_df (DataFrame): Merged phenotype and race data.\n",
    "    - genes_of_interest (list): List of gene names to analyze.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    race_column = \"race\"\n",
    "    available_genes = expression_df.columns.tolist()\n",
    "    genes_to_analyze = [gene for gene in genes_of_interest if gene in available_genes]\n",
    "    missing_genes = set(genes_of_interest) - set(genes_to_analyze)\n",
    "\n",
    "    if missing_genes:\n",
    "        print(f\"Skipping missing genes: {missing_genes}\")\n",
    "    if not genes_to_analyze:\n",
    "        print(\"No genes to analyze. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for gene in genes_to_analyze:\n",
    "        print(f\"\\nAnalyzing gene: {gene}\")\n",
    "        data = pd.merge(expression_df[['sample', gene]], merged_df[['sample', race_column]], on='sample', how='inner')\n",
    "        data = data.dropna(subset=[gene, race_column])\n",
    "        race_groups = data[race_column].unique()\n",
    "\n",
    "        if len(race_groups) < 2:\n",
    "            print(\"Not enough race groups for comparison. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        group_data = [data[data[race_column] == group][gene] for group in race_groups]\n",
    "        if sum(len(g) >= 3 for g in group_data) < 2:\n",
    "            print(\"Not enough data in groups for statistical comparison. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        f_stat, p_value = stats.f_oneway(*group_data)\n",
    "        print(f\"ANOVA results for {gene}: F-statistic = {f_stat:.4f}, P-value = {p_value:.4e}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x=race_column, y=gene, data=data)\n",
    "        sns.swarmplot(x=race_column, y=gene, data=data, color=\".25\")\n",
    "        plt.title(f\"Expression of {gene} by Race\\nANOVA P-value = {p_value:.4e}\")\n",
    "        plt.ylabel(\"Expression Level\")\n",
    "        plt.xlabel(\"Race\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading phenotype data...\n",
      "Merged phenotype data with race.\n",
      "Filtering expression data...\n",
      "Loading filtered data into DataFrame...\n",
      "Distinct races and their counts:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define working directory and file paths\n",
    "working_dir = \"/data/expression/\"\n",
    "xml_dir = f\"{working_dir}/xml_files\"\n",
    "phenotype_file = f\"{working_dir}TcgaTargetGTEX_phenotype.txt\"\n",
    "expression_file = f\"{working_dir}TcgaTargetGtex_RSEM_Hugo_norm_count\"\n",
    "genes_of_interest = [\"MMP9\"]\n",
    "\n",
    "# Step 2: Load ethnicity data from XML files\n",
    "race_df = load_race_data(xml_dir)\n",
    "\n",
    "# Step 3: Load and merge phenotype data with ethnicity\n",
    "phenotype_df = load_phenotype_data(phenotype_file, race_df)\n",
    "\n",
    "# Step 4: Load expression data\n",
    "samples = phenotype_df['sample'].tolist()  # Get the list of sample IDs from phenotype data\n",
    "expression_df = load_expression_data(expression_file, samples, genes_of_interest)\n",
    "\n",
    "\n",
    "# Optional: Print distinct ethnicities and their counts\n",
    "print(\"Distinct races and their counts:\")\n",
    "print(phenotype_df['race'].value_counts())\n",
    "\n",
    "# Step 5: Analyze gene expression by race\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_exp_df = expression_df.T\n",
    "transposed_exp_df.columns = transposed_exp_df.iloc[0]\n",
    "transposed_exp_df = transposed_exp_df[1:]\n",
    "# reindex making the actual index named sample a column named sample\n",
    "transposed_exp_df = transposed_exp_df.reset_index()\n",
    "# rename the index to sample\n",
    "transposed_exp_df = transposed_exp_df.rename(columns={'index': 'sample'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing gene: MMP9\n",
      "Not enough race groups for comparison. Skipping.\n"
     ]
    }
   ],
   "source": [
    "analyze_gene_expression_by_race (transposed_exp_df, phenotype_df, genes_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
